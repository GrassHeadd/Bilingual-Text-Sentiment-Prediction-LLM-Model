{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c232ad33",
   "metadata": {},
   "source": [
    "# Format the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 3 dataset and process them accordingly\n",
    "\n",
    "viet_data =load_dataset(\"../data/vietnamese_train_samples.csv\")\n",
    "fingpt_data = load_dataset(\"../data/fingpt_train_samples.csv\")\n",
    "synthesized_data = load_dataset(\"../data/synthetic_data_generate.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2301c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and proces the validation dataset\n",
    "viet_data_val = load_dataset(\"../data/vietnamese_validation_samples.csv\")\n",
    "fingpt_data_val = load_dataset(\"../data/fingpt_validation_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment     topic  \\\n",
      "0                                     em thấy ổn ạ .   neutral    others   \n",
      "1     giảng viên lên lớp đúng giờ , dạy nhiệt tình .  positive  lecturer   \n",
      "2                                  tại do tuần thi .   neutral    others   \n",
      "3  thầy dạy hài hước , tận tâm trước các vấn đề v...  positive  lecturer   \n",
      "4              giảng viên dạy nhiệt tình , tận tâm .  positive  lecturer   \n",
      "\n",
      "   length  word_count                                          tokenized  \\\n",
      "0      14           5                                     em thấy ổn ạ .   \n",
      "1      46          11     giảng_viên lên_lớp đúng giờ , dạy nhiệt_tình .   \n",
      "2      17           5                                  tại do tuần thi .   \n",
      "3      89          22  thầy dạy hài_hước , tận_tâm trước các vấn_đề v...   \n",
      "4      37           9              giảng_viên dạy nhiệt_tình , tận_tâm .   \n",
      "\n",
      "                                    sentence_cleaned  \\\n",
      "0                                       em thấy ổn ạ   \n",
      "1         giảng_viên lên_lớp đúng giờ dạy nhiệt_tình   \n",
      "2                                           tuần thi   \n",
      "3  thầy dạy hài_hước tận_tâm trước vấn_đề học_tập...   \n",
      "4                  giảng_viên dạy nhiệt_tình tận_tâm   \n",
      "\n",
      "                                 sentence_words_list  \n",
      "0                          ['em', 'thấy', 'ổn', 'ạ']  \n",
      "1  ['giảng_viên', 'lên_lớp', 'đúng', 'giờ', 'dạy'...  \n",
      "2                                    ['tuần', 'thi']  \n",
      "3  ['thầy', 'dạy', 'hài_hước', 'tận_tâm', 'trước'...  \n",
      "4     ['giảng_viên', 'dạy', 'nhiệt_tình', 'tận_tâm']  \n"
     ]
    }
   ],
   "source": [
    "print(viet_data_val.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11698ae3",
   "metadata": {},
   "source": [
    "2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data to instruction format\n",
    "\n",
    "for i in range(len(fingpt_data)):\n",
    "    input = fingpt_data['input'][i]\n",
    "    instruction = fingpt_data['instruction'][i]\n",
    "    user_msg = \"\\\"\" + input + \"\\\"\" + \" \" + instruction\n",
    "    fingpt_data.at[i, 'user_msg'] = user_msg\n",
    "\n",
    "vi_instruction = \"Phân loại cảm xúc của câu này là gì? Hãy chọn câu trả lời từ {negative/neutral/positive}.\"\n",
    "for i in range(len(viet_data)):\n",
    "    input = viet_data['sentence'][i]\n",
    "    topic = viet_data['topic'][i]\n",
    "    user_msg = \"\\\"\" + input + \"\\\"\" + \" \" + vi_instruction + \" Đây là chủ đề: \" + topic\n",
    "    viet_data.at[i, 'user_msg'] = user_msg\n",
    "    \n",
    "for i in range(len(synthesized_data)):\n",
    "    input = synthesized_data['input'][i]\n",
    "    instruction = synthesized_data['instruction'][i]\n",
    "    user_msg = \"\\\"\" + input + \"\\\"\" + \" \" + instruction\n",
    "    synthesized_data.at[i, 'user_msg'] = user_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e64dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(viet_data_val)):\n",
    "    input = viet_data_val['sentence'][i]\n",
    "    topic = viet_data_val['topic'][i]\n",
    "    user_msg = \"\\\"\" + input + \"\\\"\" + \" \" + vi_instruction + \" Đây là chủ đề: \" + topic\n",
    "    viet_data_val.at[i, 'user_msg'] = user_msg\n",
    "for i in range(len(fingpt_data_val)):\n",
    "    input = fingpt_data_val['input'][i]\n",
    "    instruction = fingpt_data_val['instruction'][i]\n",
    "    user_msg = \"\\\"\" + input + \"\\\"\" + \" \" + instruction\n",
    "    fingpt_data_val.at[i, 'user_msg'] = user_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingpt_subset = pd.DataFrame({\n",
    "    'user_msg': fingpt_data['user_msg'],\n",
    "    'output': fingpt_data['output'],\n",
    "})\n",
    "\n",
    "viet_subset = pd.DataFrame({\n",
    "    'user_msg': viet_data['user_msg'],\n",
    "    'output': viet_data['sentiment'],\n",
    "})\n",
    "\n",
    "synth_subset = pd.DataFrame({\n",
    "    'user_msg': synthesized_data['user_msg'],\n",
    "    'output': synthesized_data['output'],\n",
    "})\n",
    "\n",
    "combined_data = pd.concat([fingpt_subset, viet_subset, synth_subset], ignore_index=True)\n",
    "combined_data = combined_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "combined_data.head()\n",
    "\n",
    "combined_data.to_csv(\"../data/combined_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_msg</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Is Now The Time To Look At Buying Avaya Holdi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"'Mad Money' host Jim Cramer and the 'Squawk o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"mong thầy vẫn giữa phong độ như thế ;) .\" Phâ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"nhiệt tình , tận tâm , hài hước , famous name...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The Department of Justice could sue Apple by ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            user_msg    output\n",
       "0  \"Is Now The Time To Look At Buying Avaya Holdi...   neutral\n",
       "1  \"'Mad Money' host Jim Cramer and the 'Squawk o...  negative\n",
       "2  \"mong thầy vẫn giữa phong độ như thế ;) .\" Phâ...   neutral\n",
       "3  \"nhiệt tình , tận tâm , hài hước , famous name...  positive\n",
       "4  \"The Department of Justice could sue Apple by ...   neutral"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viet_val_subset = pd.DataFrame({\n",
    "    'user_msg': viet_data_val['user_msg'],\n",
    "    'output': viet_data_val['sentiment'],\n",
    "})\n",
    "fingpt_val_subset = pd.DataFrame({\n",
    "    'user_msg': fingpt_data_val['user_msg'],\n",
    "    'output': fingpt_data_val['output'],\n",
    "})\n",
    "combined_val_data = pd.concat([viet_val_subset, fingpt_val_subset], ignore_index=True)\n",
    "combined_val_data = combined_val_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "combined_val_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d41374",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_val_data.to_csv(\"../data/combined_val_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d4451",
   "metadata": {},
   "source": [
    "3. Template Application\n",
    "    - Apply the appropriate chat template for your model\n",
    "    - Insert all necessary special tokens\n",
    "    - Format conversations correctly for the tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
